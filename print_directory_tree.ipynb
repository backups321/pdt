{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This is the Jupyter Notebook version of main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "import pathlib\n",
    "import glob\n",
    "import unicodedata\n",
    "\n",
    "def print_directory_tree(path, layer_num=0, last_dir=False, indent_current='    ', count=0, max_file_num=3, dictionary = {}, arrow = False, tabs_num = 10):\n",
    "    \"\"\"Print out the directory structure of the input path in a tree\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    path : str\n",
    "        The path of the project whose directory structure you want to print.\n",
    "\n",
    "    layer_num : int, optional\n",
    "        The current layer number (default is 0).\n",
    "\n",
    "    last_dir : bool, optional\n",
    "        Specifies whether the current directory is the last one in the parent directory.\n",
    "\n",
    "    indent_current : str, optional\n",
    "        The string used for indentation at the current layer (default is four spaces '    ').\n",
    "\n",
    "    count : int, optional\n",
    "        A counter used for tracking the number of files within a specific folder.\n",
    "\n",
    "    max_file_num : int, optional\n",
    "        The maximum number of files to print within a single folder.\n",
    "\n",
    "    dictionary : dict, optional\n",
    "        A dictionary containing descriptions for directory names.\n",
    "\n",
    "    arrow : bool, optional\n",
    "        Specifies whether to include arrow symbols to indicate the hierarchy (default is False).\n",
    "\n",
    "    tabs_num : int, optional\n",
    "        The number of tabs used for indentation in the tree structure (default is 10).\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure the path is absolute\n",
    "    if not pathlib.Path(path).is_absolute():\n",
    "        path = str(pathlib.Path(path).resolve())\n",
    "\n",
    "    # Get the current directory name\n",
    "    current_dir = os.path.basename(path)\n",
    "\n",
    "    # Print the current directory (folders)\n",
    "    if layer_num == 0:\n",
    "        print(current_dir)\n",
    "    else:\n",
    "        branch = '└─ ' if last_dir else '├─ '\n",
    "        description = dictionary.get(current_dir, '')\n",
    "        output_format = '{indent}{branch}{dirname}{description}'\n",
    "        indent = ' '*((tabs_num - layer_num) * 6 - sum(2 if unicodedata.east_asian_width(c) in 'FWA' else 1 for c in current_dir)) if arrow == True else ''\n",
    "        branch_format = ('<- ' if layer_num == 1 else ' <- ') if arrow == True else ''\n",
    "        print(output_format.format(indent=indent_current, branch=branch, dirname=current_dir, description=(indent + branch_format + description) if description else ''))\n",
    "\n",
    "    # Get paths in the current directory\n",
    "    paths = [p for p in glob.glob(os.path.join(path, '*')) if os.path.isdir(p) or os.path.isfile(p)]\n",
    "    paths.sort()\n",
    "    \n",
    "    # Print the current directory (files)\n",
    "    for i, p in enumerate(paths):\n",
    "        indent_lower = indent_current\n",
    "\n",
    "        if layer_num != 0:\n",
    "            indent_lower += '     ' if last_dir else '│    '\n",
    "\n",
    "        if os.path.isfile(p):\n",
    "            count += 1\n",
    "            branch = '└─ ' if i == len(paths) - 1 else '├─ '\n",
    "\n",
    "            if count > max_file_num:\n",
    "                print('{indent}{branch}...'.format(indent=indent_lower, branch='└─ '))\n",
    "            else:\n",
    "                filename = os.path.basename(p)\n",
    "                description = dictionary.get(filename, '')\n",
    "                indent = ' '*((tabs_num - layer_num - 1) * 6 - sum(2 if unicodedata.east_asian_width(c) in 'FWA' else 1 for c in filename))\n",
    "                branch_format = '<- ' if layer_num == 0 else ' <- '\n",
    "                output_format = '{indent}{branch}{filename}{description}'\n",
    "                print(output_format.format(indent=indent_lower, branch=branch, filename=filename, description=(indent + branch_format + description) if description else ''))\n",
    "\n",
    "        # Recursive\n",
    "        if os.path.isdir(p):\n",
    "            count = 0\n",
    "            print_directory_tree(\n",
    "                path = p, \n",
    "                layer_num = layer_num + 1, \n",
    "                last_dir = i == len(paths) - 1, \n",
    "                indent_current = indent_lower, \n",
    "                max_file_num = max_file_num, \n",
    "                dictionary = dictionary, \n",
    "                arrow = arrow, \n",
    "                tabs_num = tabs_num\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_name\n",
      "    ├─ README.md                                             <- The top-level README for developers using this project.\n",
      "    ├─ data\n",
      "    │    ├─ label                                            <- label data\n",
      "    │    │    └─ label.json\n",
      "    │    ├─ processed                                        <- The final, canonical data sets for modeling.\n",
      "    │    │    ├─ 1.png\n",
      "    │    │    ├─ 2.png\n",
      "    │    │    ├─ 3.png\n",
      "    │    │    └─ ...\n",
      "    │    └─ raw                                              <- The original, immutable data dump.\n",
      "    │         ├─ 1.png\n",
      "    │         ├─ 2.png\n",
      "    │         ├─ 3.png\n",
      "    │         └─ ...\n",
      "    ├─ docs                                                  <- A default Sphinx project.\n",
      "    ├─ main.ipynb                                            <- jupyter notebook version of main.py\n",
      "    ├─ main.py                                               <- run this python file\n",
      "    ├─ models                                                <- Trained and serialized models, model predictions, or model summaries.\n",
      "    │    ├─ Autoencoder_4096.h5\n",
      "    │    └─ Classifier_4096.h5\n",
      "    ├─ reports                                               <- Generated analysis as HTML, PDF, LaTeX, etc.\n",
      "    │    └─ figures                                          <- Generated graphics and figures to be used in reporting.\n",
      "    ├─ requirements.txt                                      <- The requirements file for reproducing the analysis environment, e.g. generated with `pip freeze > requirements.txt`.\n",
      "    ├─ setup.py                                              <- makes project pip installable (pip install -e .) so src can be imported.\n",
      "    └─ src                                                   <- Source code for use in this project.\n",
      "         ├─ __init__.py                                      <- Makes src a Python module.\n",
      "         ├─ dataset                                          <- Scripts to download or generate dataset.\n",
      "         │    ├─ make_dataset.py\n",
      "         │    └─ train_valid_test_split.py\n",
      "         ├─ model                                            <- Scripts to train models and then use trained models to make predictions.\n",
      "         │    ├─ predict_classifier.py\n",
      "         │    └─ train_classifier.py\n",
      "         └─ visualization                                    <- Scripts to create exploratory and results oriented visualizations.\n",
      "              └─ visualization.py\n"
     ]
    }
   ],
   "source": [
    "# A dictionary containing descriptions for directory names\n",
    "description_dictionary = {\n",
    "    'README.md':'The top-level README for developers using this project.',\n",
    "    'raw':'The original, immutable data dump.',\n",
    "    'processed':'The final, canonical data sets for modeling.',\n",
    "    'label':'label data',\n",
    "    'docs':'A default Sphinx project.',\n",
    "    'models':'Trained and serialized models, model predictions, or model summaries.',\n",
    "    'reports':'Generated analysis as HTML, PDF, LaTeX, etc.',\n",
    "    'figures':'Generated graphics and figures to be used in reporting.',\n",
    "    'requirements.txt':'The requirements file for reproducing the analysis environment, e.g. generated with `pip freeze > requirements.txt`.',\n",
    "    'setup.py':'makes project pip installable (pip install -e .) so src can be imported.',\n",
    "    'src':'Source code for use in this project.',\n",
    "    '__init__.py':'Makes src a Python module.',\n",
    "    'dataset':'Scripts to download or generate dataset.',\n",
    "    'model':'Scripts to train models and then use trained models to make predictions.',\n",
    "    'visualization':'Scripts to create exploratory and results oriented visualizations.',\n",
    "    'main.py':'run this python file',\n",
    "    'main.ipynb':'jupyter notebook version of main.py',\n",
    "}\n",
    "\n",
    "# Print out the directory structure of the input path in a tree\n",
    "print_directory_tree(\n",
    "    path='/Users/user/Desktop/project_name', \n",
    "    max_file_num = 3,\n",
    "    dictionary=description_dictionary, \n",
    "    arrow=True, \n",
    "    tabs_num = 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
